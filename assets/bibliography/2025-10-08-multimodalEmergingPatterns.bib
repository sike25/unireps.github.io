@article{DDIM,
  author       = {Jiaming Song and
                  Chenlin Meng and
                  Stefano Ermon},
  title        = {Denoising Diffusion Implicit Models},
  journal      = {CoRR},
  volume       = {abs/2010.02502},
  year         = {2020},
  url          = {https://arxiv.org/abs/2010.02502},
  eprinttype    = {arXiv},
  eprint       = {2010.02502},
  timestamp    = {Mon, 12 Oct 2020 17:53:10 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2010-02502.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{diff_survey_comprehensive,
      title={Diffusion Models: A Comprehensive Survey of Methods and Applications}, 
      author={Ling Yang and Zhilong Zhang and Yang Song and Shenda Hong and Runsheng Xu and Yue Zhao and Wentao Zhang and Bin Cui and Ming-Hsuan Yang},
      year={2023},
      eprint={2209.00796},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@ARTICLE{vision_diff_survey,
  author={Croitoru, Florinel-Alin and Hondru, Vlad and Ionescu, Radu Tudor and Shah, Mubarak},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Diffusion Models in Vision: A Survey}, 
  year={2023},
  volume={45},
  number={9},
  pages={10850-10869},
  doi={10.1109/TPAMI.2023.3261988}}

@misc{blau2022threat,
      title={Threat Model-Agnostic Adversarial Defense using Diffusion Models}, 
      author={Tsachi Blau and Roy Ganz and Bahjat Kawar and Alex Bronstein and Michael Elad},
      year={2022},
      eprint={2207.08089},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{chen2023diffusion,
      title={Diffusion Models for Imperceptible and Transferable Adversarial Attack}, 
      author={Jianqi Chen and Hao Chen and Keyan Chen and Yilan Zhang and Zhengxia Zou and Zhenwei Shi},
      year={2023},
      eprint={2305.08192},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{nie2022diffusion,
      title={Diffusion Models for Adversarial Purification}, 
      author={Weili Nie and Brandon Guo and Yujia Huang and Chaowei Xiao and Arash Vahdat and Anima Anandkumar},
      year={2022},
      eprint={2205.07460},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@misc{liu2023diffprotect,
      title={DiffProtect: Generate Adversarial Examples with Diffusion Models for Facial Privacy Protection}, 
      author={Jiang Liu and Chun Pong Lau and Rama Chellappa},
      year={2023},
      eprint={2305.13625},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{xue2023diffusionbased,
      title={Diffusion-Based Adversarial Sample Generation for Improved Stealthiness and Controllability}, 
      author={Haotian Xue and Alexandre Araujo and Bin Hu and Yongxin Chen},
      year={2023},
      eprint={2305.16494},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}



@misc{pandey2022diffusevae,
      title={DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents}, 
      author={Kushagra Pandey and Avideep Mukherjee and Piyush Rai and Abhishek Kumar},
      year={2022},
      eprint={2201.00308},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{ECGAN, title={EC-GAN: Emotion-Controllable GAN for Face Image Completion}, volume={13}, ISSN={2076-3417}, url={http://dx.doi.org/10.3390/app13137638}, DOI={10.3390/app13137638}, number={13}, journal={Applied Sciences}, publisher={MDPI AG}, author={Chen, Yueqiao and Yang, Wenxia and Fang, Xi and Han, Huan}, year={2023}, month={Jun}, pages={7638} }

@article{tian_pyramid-vae-gan_2023,
	title = {Pyramid-{VAE}-{GAN}: {Transferring} hierarchical latent variables for image inpainting},
	volume = {9},
	issn = {2096-0662},
	url = {https://doi.org/10.1007/s41095-022-0331-3},
	doi = {10.1007/s41095-022-0331-3},
	abstract = {Significant progress has been made in image inpainting methods in recent years. However, they are incapable of producing inpainting results with reasonable structures, rich detail, and sharpness at the same time. In this paper, we propose the Pyramid-VAE-GAN network for image inpainting to address this limitation. Our network is built on a variational autoencoder (VAE) backbone that encodes high-level latent variables to represent complicated high-dimensional prior distributions of images. The prior assists in reconstructing reasonable structures when inpainting. We also adopt a pyramid structure in our model to maintain rich detail in low-level latent variables. To avoid the usual incompatibility of requiring both reasonable structures and rich detail, we propose a novel cross-layer latent variable transfer module. This transfers information about long-range structures contained in high-level latent variables to low-level latent variables representing more detailed information. We further use adversarial training to select the most reasonable results and to improve the sharpness of the images. Extensive experimental results on multiple datasets demonstrate the superiority of our method. Our code is available at https://github.com/thy960112/Pyramid-VAE-GAN.},
	number = {4},
	journal = {Computational Visual Media},
	author = {Tian, Huiyuan and Zhang, Li and Li, Shijian and Yao, Min and Pan, Gang},
	month = dec,
	year = {2023},
	pages = {827--841},
}



@article{RobinHighResolution2021,
  author       = {Robin Rombach and
                  Andreas Blattmann and
                  Dominik Lorenz and
                  Patrick Esser and
                  Bj{\"{o}}rn Ommer},
  title        = {High-Resolution Image Synthesis with Latent Diffusion Models},
  journal      = {CoRR},
  volume       = {abs/2112.10752},
  year         = {2021},
  url          = {https://arxiv.org/abs/2112.10752},
  eprinttype    = {arXiv},
  eprint       = {2112.10752},
  timestamp    = {Tue, 04 Jan 2022 15:59:27 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2012-10752.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{peebles2023scalable,
      title={Scalable Diffusion Models with Transformers}, 
      author={William Peebles and Saining Xie},
      year={2023},
      eprint={2212.09748},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{kong2021diffwave,
      title={DiffWave: A Versatile Diffusion Model for Audio Synthesis}, 
      author={Zhifeng Kong and Wei Ping and Jiaji Huang and Kexin Zhao and Bryan Catanzaro},
      year={2021},
      eprint={2009.09761},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}


@misc{wu2023defending,
      title={Defending against Adversarial Audio via Diffusion Model}, 
      author={Shutong Wu and Jiongxiao Wang and Wei Ping and Weili Nie and Chaowei Xiao},
      year={2023},
      eprint={2303.01507},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}


@misc{lapid2023i,
      title={I See Dead People: Gray-Box Adversarial Attack on Image-To-Text Models}, 
      author={Raz Lapid and Moshe Sipper},
      year={2023},
      eprint={2306.07591},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@InProceedings{Xu_2019_CVPR,
author = {Xu, Yan and Wu, Baoyuan and Shen, Fumin and Fan, Yanbo and Zhang, Yong and Shen, Heng Tao and Liu, Wei},
title = {Exact Adversarial Attack to Image Captioning via Structured Output Learning With Latent Variables},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}

@ARTICLE{Aafaq_2023,
  author={Aafaq, Nayyer and Akhtar, Naveed and Liu, Wei and Shah, Mubarak and Mian, Ajmal},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Language Model Agnostic Gray-Box Adversarial Attack on Image Captioning}, 
  year={2023},
  volume={18},
  number={},
  pages={626-638},
  doi={10.1109/TIFS.2022.3226905}}


@misc{chen2018attacking,
      title={Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning}, 
      author={Hongge Chen and Huan Zhang and Pin-Yu Chen and Jinfeng Yi and Cho-Jui Hsieh},
      year={2018},
      eprint={1712.02051},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@INPROCEEDINGS{Zhang_imagination,
  author={Zhang, Shaofeng and Wang, Zheng and Xu, Xing and Guan, Xiang and Yang, Yang},
  booktitle={2020 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={Fooled by Imagination: Adversarial Attack to Image Captioning Via Perturbation in Complex Domain}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ICME46284.2020.9102842}}



@article{Wu_transferable,
author = {Wu, Hanjie and Liu, Yongtuo and Cai, Hongmin and He, Shengfeng},
title = {Learning Transferable Perturbations for Image Captioning},
year = {2022},
issue_date = {May 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1551-6857},
url = {https://doi.org/10.1145/3478024},
doi = {10.1145/3478024},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = {feb},
articleno = {57},
numpages = {18},
keywords = {Adversarial examples, robustness of neural network, image captioning}
}


@article{miosso_restricted-area_2022,
	title = {Restricted-{Area} {Adversarial} {Example} {Attack} for {Image} {Captioning} {Model}},
	volume = {2022},
	issn = {1530-8669},
	url = {https://doi.org/10.1155/2022/9962972},
	doi = {10.1155/2022/9962972},
	journal = {Wireless Communications and Mobile Computing},
	author = {Kwon, Hyun and Kim, SungHwan},
	editor = {Miosso, Cristiano Jacques},
	month = jul,
	year = {2022},
	note = {Publisher: Hindawi},
	pages = {9962972},
}

@INPROCEEDINGS{Li_backdoor2022,
  author={Li, Meiling and Zhong, Nan and Zhang, Xinpeng and Qian, Zhenxing and Li, Sheng},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Object-Oriented Backdoor Attack Against Image Captioning}, 
  year={2022},
  volume={},
  number={},
  pages={2864-2868},
  doi={10.1109/ICASSP43922.2022.9746440}}


@misc{wolf2020huggingfaces,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2020},
      eprint={1910.03771},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{carlini2018audio,
      title={Audio Adversarial Examples: Targeted Attacks on Speech-to-Text}, 
      author={Nicholas Carlini and David Wagner},
      year={2018},
      eprint={1801.01944},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{zhang_2022Audio,
  author={Zhang, Qiang and Yang, Jibin and Zhang, Xiongwei and Cao, Tieyong},
  booktitle={2022 7th International Conference on Image, Vision and Computing (ICIVC)}, 
  title={Generating Adversarial Examples in Audio Classification with Generative Adversarial Network}, 
  year={2022},
  volume={},
  number={},
  pages={848-853},
  doi={10.1109/ICIVC55077.2022.9886154}}

@inproceedings{graves_ctc2006,
author = {Graves, Alex and Fernández, Santiago and Gomez, Faustino and Schmidhuber, Jürgen},
year = {2006},
month = {01},
pages = {369-376},
title = {Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural 'networks},
volume = {2006},
journal = {ICML 2006 - Proceedings of the 23rd International Conference on Machine Learning},
doi = {10.1145/1143844.1143891}
}

@article{spectral_norm,
  author       = {Takeru Miyato and
                  Toshiki Kataoka and
                  Masanori Koyama and
                  Yuichi Yoshida},
  title        = {Spectral Normalization for Generative Adversarial Networks},
  journal      = {CoRR},
  volume       = {abs/1802.05957},
  year         = {2018},
  url          = {http://arxiv.org/abs/1802.05957},
  eprinttype    = {arXiv},
  eprint       = {1802.05957},
  timestamp    = {Mon, 13 Aug 2018 16:48:15 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1802-05957.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{vahdat2021nvae,
      title={NVAE: A Deep Hierarchical Variational Autoencoder}, 
      author={Arash Vahdat and Jan Kautz},
      year={2021},
      eprint={2007.03898},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}


@misc{xu2016show,
      title={Show, Attend and Tell: Neural Image Caption Generation with Visual Attention}, 
      author={Kelvin Xu and Jimmy Ba and Ryan Kiros and Kyunghyun Cho and Aaron Courville and Ruslan Salakhutdinov and Richard Zemel and Yoshua Bengio},
      year={2016},
      eprint={1502.03044},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{schmidt2019recurrent,
      title={Recurrent Neural Networks (RNNs): A gentle Introduction and Overview}, 
      author={Robin M. Schmidt},
      year={2019},
      eprint={1912.05911},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{staudemeyer2019understanding,
      title={Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent Neural Networks}, 
      author={Ralf C. Staudemeyer and Eric Rothstein Morris},
      year={2019},
      eprint={1909.09586},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@misc{yang2023realworld,
      title={Real-World Denoising via Diffusion Model}, 
      author={Cheng Yang and Lijing Liang and Zhixun Su},
      year={2023},
      eprint={2305.04457},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{rombach2022highresolution,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{resnet2015,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@techreport{fgvc2013,
   title         = {Fine-Grained Visual Classification of Aircraft},
   author        = {S. Maji and J. Kannala and E. Rahtu
                    and M. Blaschko and A. Vedaldi},
   year          = {2013},
   archivePrefix = {arXiv},
   eprint        = {1306.5151},
   primaryClass  = "cs-cv",
}


@misc{DDPM,
      title={Denoising Diffusion Probabilistic Models}, 
      author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
      year={2020},
      eprint={2006.11239},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{costa2023deep,
      title={How Deep Learning Sees the World: A Survey on Adversarial Attacks \& Defenses}, 
      author={Joana C. Costa and Tiago Roxo and Hugo Proença and Pedro R. M. Inácio},
      year={2023},
      eprint={2305.10862},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{reddy2023chaotic,
      title={Chaotic Variational Auto encoder-based Adversarial Machine Learning}, 
      author={Pavan Venkata Sainadh Reddy and Yelleti Vivek and Gopi Pranay and Vadlamani Ravi},
      year={2023},
      eprint={2302.12959},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@misc{wang2020atgan,
      title={AT-GAN: An Adversarial Generator Model for Non-constrained Adversarial Examples}, 
      author={Xiaosen Wang and Kun He and Chuanbiao Song and Liwei Wang and John E. Hopcroft},
      year={2020},
      eprint={1904.07793},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{bai2021aigan,
      title={AI-GAN: Attack-Inspired Generation of Adversarial Examples}, 
      author={Tao Bai and Jun Zhao and Jinlin Zhu and Shoudong Han and Jiefeng Chen and Bo Li and Alex Kot},
      year={2021},
      eprint={2002.02196},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ronneberger2015unet,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{goodfellow2015explaining,
      title={Explaining and Harnessing Adversarial Examples}, 
      author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
      year={2015},
      eprint={1412.6572},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{carlini2017evaluating,
      title={Towards Evaluating the Robustness of Neural Networks}, 
      author={Nicholas Carlini and David Wagner},
      year={2017},
      eprint={1608.04644},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@misc{madry2019deep,
      title={Towards Deep Learning Models Resistant to Adversarial Attacks}, 
      author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
      year={2019},
      eprint={1706.06083},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{cifar10,
author = {Krizhevsky, Alex},
year = {2012},
month = {05},
pages = {},
title = {Learning Multiple Layers of Features from Tiny Images},
journal = {University of Toronto}
}

@misc{fgvc,
      title={Fine-Grained Visual Classification of Aircraft}, 
      author={Subhransu Maji and Esa Rahtu and Juho Kannala and Matthew Blaschko and Andrea Vedaldi},
      year={2013},
      eprint={1306.5151},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@InProceedings{stl10,
  title = 	 {An Analysis of Single-Layer Networks in Unsupervised Feature Learning},
  author = 	 {Coates, Adam and Ng, Andrew and Lee, Honglak},
  booktitle = 	 {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {215--223},
  year = 	 {2011},
  editor = 	 {Gordon, Geoffrey and Dunson, David and Dudík, Miroslav},
  volume = 	 {15},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Fort Lauderdale, FL, USA},
  month = 	 {11--13 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v15/coates11a/coates11a.pdf}
}




@Article{jiao-multi-modal-survey,
AUTHOR = {Tianzhe Jiao and Chaopeng Guo and Xiaoyue Feng and Yuming Chen and Jie Song},
TITLE = {A Comprehensive Survey on Deep Learning Multi-Modal Fusion: Methods, Technologies and Applications},
JOURNAL = {Computers, Materials \& Continua},
VOLUME = {80},
YEAR = {2024},
NUMBER = {1},
PAGES = {1--35},
URL = {http://www.techscience.com/cmc/v80n1/57427},
ISSN = {1546-2226},
DOI = {10.32604/cmc.2024.053204}
}

@inproceedings{Radford2018ImprovingLU,
  title={Improving Language Understanding by Generative Pre-Training},
  author={Alec Radford and Karthik Narasimhan},
  year={2018},
  url={https://api.semanticscholar.org/CorpusID:49313245}
}

@article{panduru2025exploring,
  title={Exploring the unseen: A survey of multi-sensor fusion and the role of explainable ai (xai) in autonomous vehicles},
  author={Panduru, Krishna and Walsh, Joseph and others},
  journal={Sensors (Basel, Switzerland)},
  volume={25},
  number={3},
  pages={856},
  year={2025}
}


@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@misc{rombach2022highresolutionimagesynthesislatent,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.10752}, 
}

@article{zizzo2021certified,
  title={Certified Federated Adversarial Training},
  author={Zizzo, Giulio and Rawat, Ambrish and Sinn, Mathieu and Maffeis, Sergio and Hankin, Chris},
  journal={arXiv preprint arXiv:2112.10525},
  year={2021}
}

@book{kuzina_defending_2022,
	title = {Defending {Variational} {Autoencoders} from {Adversarial} {Attacks} with {MCMC}},
	abstract = {Variational autoencoders (VAEs) are deep generative models used in various domains. VAEs can generate complex objects and provide meaningful latent representations, which can be further used in downstream tasks such as classification. As previous work has shown, one can easily fool VAEs to produce unexpected latent representations and reconstructions for a visually slightly modified input. Here, we examine several objective functions for adversarial attacks construction, suggest metrics assess the model robustness, and propose a solution to alleviate the effect of an attack. Our method utilizes the Markov Chain Monte Carlo (MCMC) technique in the inference step and is motivated by our theoretical analysis. Thus, we do not incorporate any additional costs during training or we do not decrease the performance on non-attacked inputs. We validate our approach on a variety of datasets (MNIST, Fashion MNIST, Color MNIST, CelebA) and VAE configurations (\${\textbackslash}beta\$-VAE, NVAE, TC-VAE) and show that it consistently improves the model robustness to adversarial attacks.},
	author = {Kuzina, Anna and Welling, Max and Tomczak, Jakub},
	month = mar,
	year = {2022},
}

@inproceedings{roth_odds_2019,
	title = {The {Odds} are {Odd}: {A} {Statistical} {Test} for {Detecting} {Adversarial} {Examples}},
	shorttitle = {The {Odds} are {Odd}},
	url = {https://proceedings.mlr.press/v97/roth19a.html},
	abstract = {We investigate conditions under which test statistics exist that can reliably detect examples, which have been adversarially manipulated in a white-box attack. These statistics can be easily computed and calibrated by randomly corrupting inputs. They exploit certain anomalies that adversarial attacks introduce, in particular if they follow the paradigm of choosing perturbations optimally under p-norm constraints. Access to the log-odds is the only requirement to defend models. We justify our approach empirically, but also provide conditions under which detectability via the suggested test statistics is guaranteed to be effective. In our experiments, we show that it is even possible to correct test time predictions for adversarial attacks with high accuracy.},
	language = {en},
	urldate = {2023-02-03},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Roth, Kevin and Kilcher, Yannic and Hofmann, Thomas},
	month = may,
	year = {2019},
	pages = {5498--5507},
}


@inproceedings{fidel_when_2020,
	title = {When {Explainability} {Meets} {Adversarial} {Learning}: {Detecting} {Adversarial} {Examples} using {SHAP} {Signatures}},
	shorttitle = {When {Explainability} {Meets} {Adversarial} {Learning}},
	doi = {10.1109/IJCNN48605.2020.9207637},
	abstract = {State-of-the-art deep neural networks (DNNs) are highly effective in solving many complex real-world problems. However, these models are vulnerable to adversarial perturbation attacks, and despite the plethora of research in this domain, to this day, adversaries still have the upper hand in the cat and mouse game of adversarial example generation methods vs. detection and prevention methods. In this research, we present a novel detection method that uses Shapley Additive Explanations (SHAP) values computed for the internal layers of a DNN classifier to discriminate between normal and adversarial inputs. We evaluate our method by building an extensive dataset of adversarial examples over the popular CIFAR-10 and MNIST datasets, and training a neural network-based detector to distinguish between normal and adversarial inputs. We evaluate our detector against adversarial examples generated by diverse state-of-the-art attacks and demonstrate its high detection accuracy and strong generalization ability to adversarial inputs generated with different attack methods.},
	booktitle = {2020 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Fidel, Gil and Bitton, Ron and Shabtai, Asaf},
	month = jul,
	year = {2020},
	note = {ISSN: 2161-4407},
	keywords = {Adversarial Learning, Artificial intelligence, Automobiles, Cats, Deep Learning, Detectors, Explainable AI, Neurons, Perturbation methods, SHAP, Training},
	pages = {1--8},
}



@inproceedings{tramer_adaptive_2020,
	title = {On {Adaptive} {Attacks} to {Adversarial} {Example} {Defenses}},
	volume = {33},
	url = {https://proceedings.nips.cc/paper/2020/hash/11f38f8ecd71867b42433548d1078e38-Abstract.html},
	abstract = {Adaptive attacks have (rightfully) become the de facto standard for evaluating defenses to adversarial examples. We find, however, that typical adaptive evaluations are incomplete.
We demonstrate that 13 defenses recently published at ICLR, ICML and NeurIPS---and which illustrate a diverse set of defense strategies---can be circumvented despite attempting to perform evaluations using adaptive attacks.},
	urldate = {2023-02-15},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Tramer, Florian and Carlini, Nicholas and Brendel, Wieland and Madry, Aleksander},
	year = {2020},
	pages = {1633--1645},
}


@article{guo_detecting_2019,
	title = {Detecting adversarial examples via prediction difference for deep neural networks},
	volume = {501},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025519305110},
	doi = {10.1016/j.ins.2019.05.084},
	language = {en},
	urldate = {2023-02-03},
	journal = {Information Sciences},
	author = {Guo, Feng and Zhao, Qingjie and Li, Xuan and Kuang, Xiaohui and Zhang, Jianwei and Han, Yahong and Tan, Yu-an},
	month = oct,
	year = {2019},
	keywords = {Adversarial example, Deep neural network, Image recognition, Prediction difference},
	pages = {182--192},
}


@article{zhang2021defense,
  title={Defense against adversarial attacks by reconstructing images},
  author={Zhang, Shudong and Gao, Haichang and Rao, Qingxun},
  journal={IEEE Transactions on Image Processing},
  volume={30},
  pages={6117--6129},
  year={2021},
  publisher={IEEE}
}

@misc{nie_diffusion_2022,
	title = {Diffusion {Models} for {Adversarial} {Purification}},
	url = {http://arxiv.org/abs/2205.07460},
	abstract = {Adversarial purification refers to a class of defense methods that remove adversarial perturbations using a generative model. These methods do not make assumptions on the form of attack and the classification model, and thus can defend pre-existing classifiers against unseen threats. However, their performance currently falls behind adversarial training methods. In this work, we propose DiffPure that uses diffusion models for adversarial purification: Given an adversarial example, we first diffuse it with a small amount of noise following a forward diffusion process, and then recover the clean image through a reverse generative process. To evaluate our method against strong adaptive attacks in an efficient and scalable way, we propose to use the adjoint method to compute full gradients of the reverse generative process. Extensive experiments on three image datasets including CIFAR-10, ImageNet and CelebA-HQ with three classifier architectures including ResNet, WideResNet and ViT demonstrate that our method achieves the state-of-the-art results, outperforming current adversarial training and adversarial purification methods, often by a large margin. Project page: https://diffpure.github.io.},
	urldate = {2023-02-23},
	publisher = {arXiv},
	author = {Nie, Weili and Guo, Brandon and Huang, Yujia and Xiao, Chaowei and Vahdat, Arash and Anandkumar, Anima},
	month = may,
	year = {2022},
	note = {arXiv:2205.07460 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}


@inproceedings{yoon_adversarial_2021,
	title = {Adversarial {Purification} with {Score}-based {Generative} {Models}},
	url = {https://proceedings.mlr.press/v139/yoon21a.html},
	abstract = {While adversarial training is considered as a standard defense method against adversarial attacks for image classifiers, adversarial purification, which purifies attacked images into clean images with a standalone purification, model has shown promises as an alternative defense method. Recently, an EBM trained with MCMC has been highlighted as a purification model, where an attacked image is purified by running a long Markov-chain using the gradients of the EBM. Yet, the practicality of the adversarial purification using an EBM remains questionable because the number of MCMC steps required for such purification is too large. In this paper, we propose a novel adversarial purification method based on an EBM trained with DSM. We show that an EBM trained with DSM can quickly purify attacked images within a few steps. We further introduce a simple yet effective randomized purification scheme that injects random noises into images before purification. This process screens the adversarial perturbations imposed on images by the random noises and brings the images to the regime where the EBM can denoise well. We show that our purification method is robust against various attacks and demonstrate its state-of-the-art performances.},
	language = {en},
	urldate = {2023-02-23},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Yoon, Jongmin and Hwang, Sung Ju and Lee, Juho},
	month = jul,
	year = {2021},
	pages = {12062--12072},
}


@misc{haarnoja2018softactorcritic,
      title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor}, 
      author={Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
      year={2018},
      eprint={1801.01290},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1801.01290}, 
}

@inproceedings{todorov2012mujoco,
  title={MuJoCo: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE},
  doi={10.1109/IROS.2012.6386109}
}

@article{towers2024gymnasium,
  title={Gymnasium: A Standard Interface for Reinforcement Learning Environments},
  author={Towers, Mark and Kwiatkowski, Ariel and Terry, Jordan and Balis, John U and De Cola, Gianluca and Deleu, Tristan and Goul{\~a}o, Manuel and Kallinteris, Andreas and Krimmel, Markus and KG, Arjun and others},
  journal={arXiv preprint arXiv:2407.17032},
  year={2024}
}

@ARTICLE{chi_autonomous_survey2024,
  author={Chi, Lijun and Msahli, Mounira and Zhang, Qingjie and Qiu, Han and Zhang, Tianwei and Memmi, Gerard and Qiu, Meikang},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={Adversarial Attacks on Autonomous Driving Systems in the Physical World: a Survey}, 
  year={2024},
  volume={},
  number={},
  pages={1-22},
  keywords={Sensors;Cameras;Point cloud compression;Laser radar;Autonomous vehicles;Millimeter wave radar;Visualization;Three-dimensional displays;Radar detection;Intelligent vehicles;Adversarial attacks;adversarial examples;black-box attacks;autonomous driving systems;environment perception},
  doi={10.1109/TIV.2024.3484152}}

@ARTICLE{roheda2021multimodal,
  author={Roheda, Siddharth and Krim, Hamid and Riggan, Benjamin S.},
  journal={IEEE Sensors Journal}, 
  title={Robust Multi-Modal Sensor Fusion: An Adversarial Approach}, 
  year={2021},
  volume={21},
  number={2},
  pages={1885-1896},
  keywords={Sensor fusion;Sensor phenomena and characterization;Generators;Sensor systems;Generative adversarial networks;Feature extraction;Multi-modal sensors;target detection;Generative Adversarial Networks (GAN);Event Driven Fusion},
  doi={10.1109/JSEN.2020.3018698}}

@misc{wu2025dissectingadversarialrobustnessmultimodal,
      title={Dissecting Adversarial Robustness of Multimodal LM Agents}, 
      author={Chen Henry Wu and Rishi Shah and Jing Yu Koh and Ruslan Salakhutdinov and Daniel Fried and Aditi Raghunathan},
      year={2025},
      eprint={2406.12814},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.12814}, 
}

@misc{wang2025manipulatingmultimodalagentscrossmodal,
      title={Manipulating Multimodal Agents via Cross-Modal Prompt Injection}, 
      author={Le Wang and Zonghao Ying and Tianyuan Zhang and Siyuan Liang and Shengshan Hu and Mingchuan Zhang and Aishan Liu and Xianglong Liu},
      year={2025},
      eprint={2504.14348},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.14348}, 
}



@INPROCEEDINGS{shayanNDVAE,

  author={Jalalipour, Shayan and Rekabdar, Banafsheh},

  booktitle={2023 Fifth International Conference on Transdisciplinary AI (TransAI)}, 

  title={Noisy-Defense Variational Auto-Encoder (ND-VAE): An Adversarial Defense Framework to Eliminate Adversarial Attacks}, 

  year={2023},

  volume={},

  number={},

  pages={50-57},

  keywords={Training;Resistance;Costs;Purification;Perturbation methods;Noise measurement;Artificial intelligence;Adversarial Attack;Hierarchical Variational Autoencoder;Adversarial Defense;Variational Autoencoder;Adversarial Purification},

  doi={10.1109/TransAI60598.2023.00018}}


@misc{li2019defensevaefastaccuratedefense,
      title={Defense-VAE: A Fast and Accurate Defense against Adversarial Attacks}, 
      author={Xiang Li and Shihao Ji},
      year={2019},
      eprint={1812.06570},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1812.06570}, 
}


@misc{li2024learningmultimodalbehaviorsscratch,
      title={Learning Multimodal Behaviors from Scratch with Diffusion Policy Gradient}, 
      author={Zechu Li and Rickmer Krohn and Tao Chen and Anurag Ajay and Pulkit Agrawal and Georgia Chalvatzaki},
      year={2024},
      eprint={2406.00681},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.00681}, 
}

@INPROCEEDINGS{GolchinAnomolyDetection,

  author={Golchin, Bahareh and Rekabdar, Banafsheh},

  booktitle={2024 Conference on AI, Science, Engineering, and Technology (AIxSET)}, 

  title={Anomaly Detection In Time Series Data Using Reinforcement Learning, Variational Autoencoder, and Active Learning}, 

  year={2024},

  volume={},

  number={},

  pages={1-8},

  keywords={Adaptation models;Large language models;Time series analysis;Finance;Manuals;Deep reinforcement learning;Data models;Anomaly detection;Long short term memory;Tuning;Anomaly detection;Deep reinforcement learning;Variational autoencoder;Active learning;Long short-term memory;Generative AI},

  doi={10.1109/AIxSET62544.2024.00007}}


@article{scikit-learn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}
